@inproceedings{louDiscreteDiffusionModeling2024,
  title = {Discrete {{Diffusion Modeling}} by {{Estimating}} the {{Ratios}} of the {{Data Distribution}}},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Lou, Aaron and Lim, Chenlin and Katariya, Isay and Ermon, Stefano},
  year = {2024},
  series = {{{PMLR}}},
  volume = {235},
  pages = {32103--32138},
  publisher = {{PMLR}},
  address = {{Vienna, Austria}},
  abstract = {Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel loss that naturally extends score matching to discrete spaces, modeled by estimating the ratios of the data distribution. We test our method on a suite of tasks including ordinal regression, pixel-level image modeling, and natural language generation. Across all tasks, we find improvements over existing discrete diffusion models and achieve new state-of-the-art results on several benchmarks.},
  url = {https://proceedings.mlr.press/v235/lou24a.html}
}

@inproceedings{gatDiscreteFlowMatching2024,
  title = {Discrete {{Flow Matching}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Gat, Itai and Remez, Tal and Perez-Cruz, Fernando and Schwing, Alexander G. and Lipman, Yaron},
  year = {2024},
  volume = {37},
  pages = {78321--78342},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Despite Flow Matching and diffusion models having emerged as powerful generative paradigms for continuous data, their application to discrete data remains limited. In this work, we present Discrete Flow Matching, a novel approach that extends Flow Matching to discrete spaces. Our method addresses the challenges of discrete data generation by leveraging the continuous-time Markov chain framework and introducing a tractable objective for training generative models on discrete domains. We demonstrate the effectiveness of our approach on various discrete data types, including text and molecular graphs, showing competitive or superior performance compared to existing discrete diffusion models.},
  url = {https://papers.nips.cc/paper_files/paper/2024/hash/discrete-flow-matching.pdf}
}